{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11639182,"sourceType":"datasetVersion","datasetId":7303180}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install transformers torchaudio\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!pip install pyctcdecode\n#!pip install https://github.com/kpu/kenlm/archive/master.zip\n#import kenlm  \n#import pyctcdecode.decoder  \n#pyctcdecode.decoder.kenlm = kenlm \n#restart session after this plzzzzzzz","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport librosa\n\n\nfrom transformers import AutoProcessor, AutoModelForCTC\n\nprocessor = Wav2Vec2Processor.from_pretrained(\"jonatasgrosman/wav2vec2-large-xlsr-53-french\")\nmodel = Wav2Vec2ForCTC.from_pretrained(\"jonatasgrosman/wav2vec2-large-xlsr-53-french\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T14:42:55.842381Z","iopub.execute_input":"2025-05-01T14:42:55.842966Z","iopub.status.idle":"2025-05-01T14:42:57.233816Z","shell.execute_reply.started":"2025-05-01T14:42:55.842943Z","shell.execute_reply":"2025-05-01T14:42:57.233203Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T14:42:59.413563Z","iopub.execute_input":"2025-05-01T14:42:59.414309Z","iopub.status.idle":"2025-05-01T14:42:59.419883Z","shell.execute_reply.started":"2025-05-01T14:42:59.414283Z","shell.execute_reply":"2025-05-01T14:42:59.419219Z"}},"outputs":[{"name":"stdout","text":"Wav2Vec2ForCTC(\n  (wav2vec2): Wav2Vec2Model(\n    (feature_extractor): Wav2Vec2FeatureEncoder(\n      (conv_layers): ModuleList(\n        (0): Wav2Vec2LayerNormConvLayer(\n          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation): GELUActivation()\n        )\n        (1-4): 4 x Wav2Vec2LayerNormConvLayer(\n          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation): GELUActivation()\n        )\n        (5-6): 2 x Wav2Vec2LayerNormConvLayer(\n          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation): GELUActivation()\n        )\n      )\n    )\n    (feature_projection): Wav2Vec2FeatureProjection(\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (projection): Linear(in_features=512, out_features=1024, bias=True)\n      (dropout): Dropout(p=0.05, inplace=False)\n    )\n    (encoder): Wav2Vec2EncoderStableLayerNorm(\n      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n        (conv): ParametrizedConv1d(\n          1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n          (parametrizations): ModuleDict(\n            (weight): ParametrizationList(\n              (0): _WeightNorm()\n            )\n          )\n        )\n        (padding): Wav2Vec2SamePadLayer()\n        (activation): GELUActivation()\n      )\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.05, inplace=False)\n      (layers): ModuleList(\n        (0-23): 24 x Wav2Vec2EncoderLayerStableLayerNorm(\n          (attention): Wav2Vec2SdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (dropout): Dropout(p=0.05, inplace=False)\n          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (feed_forward): Wav2Vec2FeedForward(\n            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (output_dropout): Dropout(p=0.05, inplace=False)\n          )\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.0, inplace=False)\n  (lm_head): Linear(in_features=1024, out_features=59, bias=True)\n)\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"\nspeech, sr = librosa.load(\"/kaggle/input/dataaa2/test.mp3\", sr=16000)\n#must be 16000 cause it says \"When using this model, make sure that your speech input is sampled at 16kHz.\"\ninput_values = processor(speech, return_tensors=\"pt\", sampling_rate=16000,padding=True).input_values\nwith torch.no_grad():\n    logits = model(input_values).logits\npredicted_ids = torch.argmax(logits,dim=-1)\ntranscription = processor.batch_decode(predicted_ids)\nprint(transcription[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T14:48:08.509174Z","iopub.execute_input":"2025-05-01T14:48:08.509524Z","iopub.status.idle":"2025-05-01T14:48:14.893816Z","shell.execute_reply.started":"2025-05-01T14:48:08.509504Z","shell.execute_reply":"2025-05-01T14:48:14.892910Z"}},"outputs":[{"name":"stdout","text":"quel queltierp√®tes et icaine suwicem lisansale au cinima fatait super et aussi eetale√†laatregan retoue de cotug jeles voir en film et pus afachel√© occu parpidoar atrofie au charlevor des photos e juverant la fontion profensuchi so cat√©ment sug√© dan rowens bedi afajonc 'encroet √† trolo\n","output_type":"stream"}],"execution_count":55},{"cell_type":"markdown","source":"### bad bad bad model above , good below","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\nfrom datasets import load_dataset\n\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ntorch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n\nmodel_id = \"openai/whisper-large-v3-turbo\"\n\nmodel = AutoModelForSpeechSeq2Seq.from_pretrained(\n    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n)\nmodel.to(device)\n\nprocessor = AutoProcessor.from_pretrained(model_id)\n\npipe = pipeline(\n    \"automatic-speech-recognition\",\n    model=model,\n    tokenizer=processor.tokenizer,\n    feature_extractor=processor.feature_extractor,\n    torch_dtype=torch_dtype,\n    device=device,\n)\n\n\naudio_array, sr = librosa.load(\"/kaggle/input/dataaa2/test.mp3\", sr=16000)\n\nsample = {\"array\": audio_array, \"sampling_rate\": sr}\n\nresult = pipe(sample)\nprint(result[\"text\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T14:53:48.283278Z","iopub.execute_input":"2025-05-01T14:53:48.283618Z","iopub.status.idle":"2025-05-01T14:53:52.863437Z","shell.execute_reply.started":"2025-05-01T14:53:48.283596Z","shell.execute_reply":"2025-05-01T14:53:52.862671Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\nDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n","output_type":"stream"},{"name":"stdout","text":" Qu'est-ce que tu as fait ce week-end ? Ce week-end nous sommes all√©s au cin√©ma, c'√©tait super cool et aussi on est all√©s √† le parc. Tr√®s bien. Tu vois, tu es all√© quoi ce week-end ? Je suis all√© voir un film et puis apr√®s je suis all√© au que par. Et toi ? Tranquille, moi je suis all√© voir des potos, tu vois, on a fait une petite bouffe √† un sushi, tu vois. Tu fais tellement le sushi toi ? Ouais ouais, √ßa te b√™te l√†. Franchement c'√©tait incroyable, trolo.\n","output_type":"stream"}],"execution_count":57},{"cell_type":"markdown","source":"### good enaugh now with the pheneomeme thing","metadata":{}},{"cell_type":"code","source":"#!pip install phonemizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T15:28:59.907276Z","iopub.execute_input":"2025-05-01T15:28:59.907577Z","iopub.status.idle":"2025-05-01T15:28:59.911397Z","shell.execute_reply.started":"2025-05-01T15:28:59.907556Z","shell.execute_reply":"2025-05-01T15:28:59.910525Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"#the model that does the phenomeosing \nfrom transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n\n# Load the processor and model\nprocessor = Wav2Vec2Processor.from_pretrained(\"Cnam-LMSSC/wav2vec2-french-phonemizer\")\nmodel = Wav2Vec2ForCTC.from_pretrained(\"Cnam-LMSSC/wav2vec2-french-phonemizer\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T15:28:52.212294Z","iopub.execute_input":"2025-05-01T15:28:52.213023Z","iopub.status.idle":"2025-05-01T15:28:59.657288Z","shell.execute_reply.started":"2025-05-01T15:28:52.212989Z","shell.execute_reply":"2025-05-01T15:28:59.656652Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa7e14bca18744cc907db83cae61a1f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/468 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"834a09b7d2124a17adda14d0ed9e1014"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/561 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07ce103daa154a798fca9753f8b47564"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"059da35ec7274b63811ccc91645c41d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/309 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83b0d2e1d8584686b6264eda6712131a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a25c3789060f44fbb24aa6edb805e03a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e91593b9d1e45cf8d892a8ee70e859c"}},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"#print(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T15:29:09.711627Z","iopub.execute_input":"2025-05-01T15:29:09.712248Z","iopub.status.idle":"2025-05-01T15:29:09.715501Z","shell.execute_reply.started":"2025-05-01T15:29:09.712224Z","shell.execute_reply":"2025-05-01T15:29:09.714685Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T15:45:00.316713Z","iopub.execute_input":"2025-05-01T15:45:00.317344Z","iopub.status.idle":"2025-05-01T15:45:00.320744Z","shell.execute_reply.started":"2025-05-01T15:45:00.317317Z","shell.execute_reply":"2025-05-01T15:45:00.319953Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"input_values=processor(np.array(audio_array),sampling_rate=16_000., return_tensors=\"pt\")\nwith torch.no_grad():\n  logits = model(**input_values).logits\n\npredicted_ids = torch.argmax(logits,dim = -1)\ntranscription = processor.batch_decode(predicted_ids)\n\nprint(\"Phonetic transcription : \", transcription)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T15:45:02.194385Z","iopub.execute_input":"2025-05-01T15:45:02.194663Z","iopub.status.idle":"2025-05-01T15:45:04.681845Z","shell.execute_reply.started":"2025-05-01T15:45:02.194642Z","shell.execute_reply":"2025-05-01T15:45:04.681133Z"}},"outputs":[{"name":"stdout","text":"Phonetic transcription :  ['…õk…õkk…õd…ô…õm syvik…õn lis…ëzal…õ osnimaf…õt…õ sipapy e osi …ëan alaka t Å…õbj…îÃÉ  Å…ôs d…ô k…îsvi  íle vwa Å …ëÃÉfilm py ap Åo Éle …îkypa edwa at Å Ée ma Éy Å le vÃÉ de podo syv…ëÃÉ la fimkuf…ë…ëÃÉ sy Éi k…ôtamasd wo…õs…ëÃÉ b…õÃÉda ap…ô íust≈ìÃÉ ko Å…õa p Åolo']\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"#for the prompt we focus on the top 3 pointss kids struggle with \n#when speaking french so it is what the feedback \n#strucure focuses on\n#1 nasal vowels\n# 2.Over-articulation or English/Arabic rhythm\n#3.Liaison and Final Consonant Rules","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#on the side there is always popup that give different prompt to parent //different feeback to partn fi wa9too\n#so feedback to both parent and child \n#chech it fi wa9too walla hana it is saved in resumt of what you child did today","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"promptparent = f\"\"\"\nüéß The following is a child's spoken sentence along with their phonetic transcription. Based on this and the expected French pronunciation, provide clear, structured feedback focusing on:\n\n1. Nasal vowels  \n2. Over-articulation or non-French rhythm (e.g., English or Arabic)  \n3. Liaison and final consonant rules  \n\nFor each category, indicate:\n\n‚úîÔ∏è What the child did well  \n‚ö†Ô∏è What needs improvement (with examples)  \nüéØ A suggestion or tip to improve  \n\nAlso, finish with a brief overall clarity score (e.g., from 1‚Äì5 stars).\n\n---\n\nüìù **Written sentence (child was trying to say):**  \n{result[\"text\"]}\n\nüî§ **Phonetic transcription (child's speech):**  \n{transcription}\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T16:01:03.490648Z","iopub.execute_input":"2025-05-01T16:01:03.491504Z","iopub.status.idle":"2025-05-01T16:01:03.495894Z","shell.execute_reply.started":"2025-05-01T16:01:03.491472Z","shell.execute_reply":"2025-05-01T16:01:03.495040Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"promptchild = f\"\"\"üéß The following is a child's spoken sentence along with their phonetic transcription. Based on this and the expected French pronunciation, provide simple easy to understand explanation to the child focusing on:\n1. Nasal vowels\n2. Over-articulation or non-French rhythm (e.g., English or Arabic)\n3. Liaison and final consonant rules\n\nFor each category, Explain to the child (like you are talking to him):\n\n‚úîÔ∏è What the child did well  \n‚ö†Ô∏è What needs improvement (with examples)  \nüéØ A suggestion or tip to improve\n\nAlso, finish with a brief overall clarity score (e.g., from 1‚Äì5 stars).\nüìù **Written sentence (child was trying to say):**  :${result[\"text\"]},\nüî§ **Phonetic transcription (child's speech):** :\n${transcription}\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T16:02:22.139398Z","iopub.execute_input":"2025-05-01T16:02:22.140087Z","iopub.status.idle":"2025-05-01T16:02:22.143865Z","shell.execute_reply.started":"2025-05-01T16:02:22.140048Z","shell.execute_reply":"2025-05-01T16:02:22.143095Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"from google import genai\n\nclient = genai.Client(api_key=API_KEY)\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=promptchild,\n)\n\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T16:02:25.842807Z","iopub.execute_input":"2025-05-01T16:02:25.843350Z","iopub.status.idle":"2025-05-01T16:02:31.696626Z","shell.execute_reply.started":"2025-05-01T16:02:25.843326Z","shell.execute_reply":"2025-05-01T16:02:31.695964Z"}},"outputs":[{"name":"stdout","text":"Okay, let's listen to your French! You're doing great trying to speak French, it's a tricky language! Here's what I noticed:\n\n**1. Nasal Vowels: Those Sounds Coming From Your Nose!**\n\n‚úîÔ∏è **What you did well:** You tried some nasal sounds! I heard little bits of nasalization, so you're starting to get it.\n\n‚ö†Ô∏è **What needs improvement:** Remember those sounds that feel like they're coming from your nose and mouth at the same time? It sounds like you're sometimes forgetting to make your nose vibrate! For example:\n\n*   When you said \"un film,\" the \"un\" should have a nasal \"uh\" sound.\n*   When you said \"Tr√®s bien,\" the \"bien\" should have a nasal \"ah\" sound.\n* You seem to also struggle with nasal vowels in words like \"cin√©ma\"\n\nüéØ **Suggestion/Tip:** Try pinching your nose while saying \"on\". Now, release your nose while still saying \"on\". You'll feel the vibration of air going through your nose. Do this often to learn to create the nasal vowel in \"on\". There are other nasal vowels in French, each with a different mouth shape, so learning the tip of nasalization can help you create them as well!\n\n**2. Over-Articulation and Rhythm (Like Singing the Words!)**\n\n‚úîÔ∏è **What you did well:** You are trying to pronounce all the sounds. That's great!\n\n‚ö†Ô∏è **What needs improvement:** French words are usually not pronounced with the same emphasis and \"beat\" as in English or Arabic. Sometimes, you're making each sound too clear and separate, which makes it sound a little different from how French people speak. Listen to native speakers, there is a rhythm to the sounds that is different than in Arabic and English. For example when you said \"Ce week-end nous sommes all√©s au cin√©ma, c'√©tait super cool et aussi on est all√©s √† le parc\", it sounds like all the words are equally spaced apart, try listening to how the native speakers talk in the video.\n\nüéØ **Suggestion/Tip:** Listen to French music or French cartoons. Pay attention to how the words flow together and how some syllables are stressed more than others. Try to copy the way they talk!\n\n**3. Liaison and Final Consonant Rules: Connecting and Dropping Sounds!**\n\n‚úîÔ∏è **What you did well:** You are starting to connect words!\n\n‚ö†Ô∏è **What needs improvement:** Sometimes in French, you need to pronounce consonants at the end of words when the next word starts with a vowel. This is called \"liaison.\" Also, sometimes you *don't* pronounce consonants at the end of words.\n\n*   You didn't always do the liaison when you should have. For example, \"on est all√©s\" should sound like \"on-nay-tay-lay\" (connecting the \"n\" from \"on\" to \"est\").\n*   You often pronounced final consonants which are usually dropped like in the word \"parc\".\n\nüéØ **Suggestion/Tip:** A simple way to improve is: When a word ends in a consonant like \"s, t, d, x\" and the next word starts with a vowel then you should pronounce it together. If it does not, don't pronounce the final consonant!\nExample: \"Tu es all√©\" pronounce the \"t\" at the end of \"Tu\" like \"Tu-es\".\n\n**Overall Clarity:** ‚≠ê‚≠ê¬Ω (Two and a half stars)\n\nYou're trying really hard and that's the most important thing! Keep listening to French, keep practicing, and you'll get better and better. Remember to focus on the nasal sounds, the rhythm, and when to connect the words! You've got this!\n\n","output_type":"stream"}],"execution_count":92},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
